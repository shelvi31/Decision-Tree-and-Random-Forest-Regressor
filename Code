
```
import pandas as pd

# save filepath to variable for easier access 
melbourne_file_path = '../input/melbourne-housing-snapshot/melb_data.csv' 

# read the data and store data in DataFrame titled melbourne_data 
melbourne_data = pd.read_csv(melbourne_file_path)  

# print a summary of the data in Melbourne data 
melbourne_data.describe()

# dropna drops missing values
melbourne_data = melbourne_data.dropna(axis=0)

#defining prediction target
y = melbourne_data.Price

#choosing features
melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']

#defining features data
X = melbourne_data[melbourne_features]

#Building own Model : Decision Tree Regressor ------------------------------------------------------------------
from sklearn.tree import DecisionTreeRegressor 
# Define model. Specify a number for random_state to ensure same results each run 
melbourne_model = DecisionTreeRegressor(random_state=1) 
# Fit model 
melbourne_model.fit(X, y)                   # ---------------- taking only single data set for train and test

#making predictions
print(melbourne_model.predict(X))

#calculating error
from sklearn.metrics import mean_absolute_error 
 predicted_home_prices = melbourne_model.predict(X) 
mean_absolute_error(y, predicted_home_prices)

#------------------spliting train test data
from sklearn.model_selection import train_test_split 
# split data into training and validation data, for both features and target .The split is based on a random number generator. Supplying a numeric value to  the random_state argument guarantees we get the same split every time we run this script. 

train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0) 

# ------------------- Define model  using train test this time
melbourne_model = DecisionTreeRegressor() 

# Fit model 
melbourne_model.fit(train_X, train_y) 
# get predicted prices on validation data 
val_predictions = melbourne_model.predict(val_X) 
print(mean_absolute_error(val_y, val_predictions))


#Fixing underfitting and overfitting
from sklearn.metrics import mean_absolute_error 
from sklearn.tree import DecisionTreeRegressor 
def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y): 
    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0) 
    model.fit(train_X, train_y) 
    preds_val = model.predict(val_X) 
    mae = mean_absolute_error(val_y, preds_val) 
    return(mae)

# compare MAE with differing values of max_leaf_nodes 
for max_leaf_nodes in [5, 50, 500, 5000]: 
    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y) 
    print("Max leaf nodes: %d  \t\t Mean Absolute Error:  %d" %(max_leaf_nodes, my_mae))



#--------------------using Random Forest regressor Instead of Decision Tree
from sklearn.ensemble import RandomForestRegressor 
from sklearn.metrics import mean_absolute_error 
forest_model = RandomForestRegressor(random_state=1) 
forest_model.fit(train_X, train_y) 
melb_preds = forest_model.predict(val_X) 
print(mean_absolute_error(val_y, melb_preds))
```


